{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VvKKh7BMEFaT",
    "outputId": "88a32366-7d8c-4b8c-a9c0-73821a9d16bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/danny/.local/lib/python3.8/site-packages/ipykernel_launcher.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.argv[0])\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from keras.layers import LSTM, GRU, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvmH85sVEFaX"
   },
   "outputs": [],
   "source": [
    "def load_dict_from_hdf5(filename):\n",
    "    with h5py.File(filename, 'r') as h5file:\n",
    "        return recursively_load_dict_contents_from_group(h5file, '/')\n",
    "    h5file.close()\n",
    "\n",
    "def recursively_load_dict_contents_from_group(h5file, path):\n",
    "    ans = {}\n",
    "    for key, item in h5file[path].items():\n",
    "        if isinstance(item, h5py._hl.dataset.Dataset):\n",
    "            ans[key] = item.value\n",
    "        elif isinstance(item, h5py._hl.group.Group):\n",
    "            ans[key] = recursively_load_dict_contents_from_group(h5file, path + key + '/')\n",
    "    return ans\n",
    "def convert_tensor(arg):\n",
    "    return tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "PiAqYRjxEFaa"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "SvQsM-0LD-ia",
    "outputId": "0c655725-9411-4c5f-d10b-26d5dc0c6c63"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')\n",
    "#filename = \"/content/drive/My Drive/Colab/2011+2012.hdf5\"\n",
    "#filename2 = \"/content/drive/My Drive/Colab/2012_valid.hdf5\"\n",
    "#data = load_dict_from_hdf5(filename)\n",
    "#vdata = load_dict_from_hdf5(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-74920beda866>:10: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  ans[key] = item.value\n"
     ]
    }
   ],
   "source": [
    "filename = \"/home/danny/Projects/crohme-data-extractor/train.hdf5\"\n",
    "train_data = load_dict_from_hdf5(filename)\n",
    "\n",
    "filename = \"/home/danny/Projects/crohme-data-extractor/validation.hdf5\"\n",
    "val_data = load_dict_from_hdf5(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "unique_labels = {}\n",
    "\n",
    "def to_lists(data):\n",
    "    labels_lst = []\n",
    "    curves_lst = []\n",
    "    max_curves = 0\n",
    "    for a in data:\n",
    "        for b in data[a]:\n",
    "            label = data[a][b]['label']\n",
    "            if(label not in unique_labels): unique_labels[label] = 1\n",
    "            labels_lst.append(label)\n",
    "            sample = np.concatenate(list(data[a][b]['feat_bez_curves'].values()))\n",
    "            sample = np.nan_to_num(sample)\n",
    "            curves_lst.append(sample)\n",
    "            max_curves = max(max_curves,sample.shape[0])\n",
    "    return curves_lst, labels_lst, max_curves\n",
    "        \n",
    "#From here: https://stackoverflow.com/questions/57346556/creating-a-ragged-tensor-from-a-list-of-tensors\n",
    "def stack_ragged(tensors):\n",
    "    values = tf.concat(tensors, axis=0)\n",
    "    lens = tf.stack([tf.shape(t, out_type=tf.int64)[0] for t in tensors])\n",
    "    return tf.RaggedTensor.from_row_lengths(values, lens)\n",
    "\n",
    "def stack_dense(tensors,max_curves):\n",
    "    pad = lambda x:np.pad(x, pad_width=((0,max_curves-len(x)),(0,0)))\n",
    "    return np.concatenate([np.expand_dims(pad(x),0) for x in tensors],axis=0)\n",
    "def encode_labels(labels,fit=True):\n",
    "    if(fit): label_encoder.fit(labels)\n",
    "    integer_encoded = label_encoder.transform(labels)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    if(fit): onehot_encoder.fit(integer_encoded)\n",
    "    onehot_encoded = onehot_encoder.transform(integer_encoded)\n",
    "    return onehot_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process train_data\n",
    "curves_lst, labels_lst, max_curves = to_lists(train_data)\n",
    "#X_train = stack_ragged(curves_lst)\n",
    "X_train = stack_dense(curves_lst,max_curves)\n",
    "Y_train = encode_labels(np.array(labels_lst))\n",
    "\n",
    "#This is just a for a sanity check\n",
    "x_unq = unique_labels\n",
    "A = label_encoder.transform(sorted(list(x_unq.keys())))\n",
    "unique_labels = {}\n",
    "\n",
    "#Process val_data\n",
    "curves_lst, labels_lst, max_curves = to_lists(val_data)\n",
    "#X_val = stack_ragged(curves_lst)\n",
    "X_val = stack_dense(curves_lst,max_curves)\n",
    "Y_val = encode_labels(np.array(labels_lst),fit=False)\n",
    "\n",
    "#This is just a for a sanity check\n",
    "B = label_encoder.transform(sorted(list(unique_labels.keys())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100]\n",
      "(102772, None, 9)\n",
      "(102772, 101)\n",
      "(12487, None, 9)\n",
      "(12487, 101)\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print(B)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 14.08450704  18.30985915  -9.85915493  81.69014085   0.12010874\n",
      "   -0.9055069   21.78027361  30.09209851   1.        ]\n",
      " [  4.22535211 100.          25.35211268 -14.08450704  -0.5070985\n",
      "   -0.27829966  12.0068625   10.54683918   0.        ]\n",
      " [ 29.57746479  85.91549296  11.26760563 -85.91549296  -0.19134725\n",
      "   -0.13040331  32.67898951  26.98834631   0.        ]\n",
      " [ 40.84507042   0.         -22.53521127  14.08450704  -0.55859932\n",
      "    0.55859932  14.21732925   6.27275509  -1.        ]], shape=(4, 9), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[ 1.86046512e+01  9.30232558e+00 -1.86046512e+01  1.62790698e+01\n",
      "   0.00000000e+00  1.66533454e-16  8.24042311e+00  8.24042311e+00\n",
      "   1.00000000e+00]\n",
      " [ 0.00000000e+00  2.55813953e+01  3.95348837e+01  6.51162791e+01\n",
      "  -5.45655055e-01 -7.03390718e-01  3.41140436e+01  3.58710836e+01\n",
      "   0.00000000e+00]\n",
      " [ 3.95348837e+01  9.06976744e+01  6.04651163e+01 -4.65116279e+01\n",
      "  -6.55695626e-01 -9.15100701e-01  3.29741638e+01  4.11668451e+01\n",
      "   0.00000000e+00]\n",
      " [ 1.00000000e+02  4.41860465e+01 -5.11627907e+01 -4.41860465e+01\n",
      "  -8.58438729e-01 -6.21697711e-01  4.01401323e+01  3.94332786e+01\n",
      "   0.00000000e+00]\n",
      " [ 4.88372093e+01  0.00000000e+00 -2.32558140e+01  1.39534884e+01\n",
      "  -5.40419500e-01 -1.03037683e+00  1.20044535e+01  1.51920406e+01\n",
      "  -1.00000000e+00]], shape=(5, 9), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#Two samples labelled '0'\n",
    "print(X_train[102737]) \n",
    "print(X_val[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U33mviQqG2sC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3212/3212 [==============================] - 126s 39ms/step - loss: 1.4546 - accuracy: 0.6481 - top5_acc: 0.8558 - val_loss: 0.8949 - val_accuracy: 0.7785 - val_top5_acc: 0.9276\n",
      "Epoch 2/25\n",
      "3212/3212 [==============================] - 126s 39ms/step - loss: 0.7530 - accuracy: 0.8011 - top5_acc: 0.9522 - val_loss: 0.7139 - val_accuracy: 0.8109 - val_top5_acc: 0.9481\n",
      "Epoch 3/25\n",
      "3212/3212 [==============================] - 127s 40ms/step - loss: 0.6504 - accuracy: 0.8210 - top5_acc: 0.9634 - val_loss: 0.6811 - val_accuracy: 0.8210 - val_top5_acc: 0.9530\n",
      "Epoch 4/25\n",
      "3212/3212 [==============================] - 131s 41ms/step - loss: 0.5850 - accuracy: 0.8368 - top5_acc: 0.9689 - val_loss: 0.6160 - val_accuracy: 0.8378 - val_top5_acc: 0.9632\n",
      "Epoch 5/25\n",
      "3212/3212 [==============================] - 135s 42ms/step - loss: 0.5515 - accuracy: 0.8441 - top5_acc: 0.9725 - val_loss: 0.6010 - val_accuracy: 0.8326 - val_top5_acc: 0.9641\n",
      "Epoch 6/25\n",
      "3212/3212 [==============================] - 143s 45ms/step - loss: 0.5327 - accuracy: 0.8478 - top5_acc: 0.9740 - val_loss: 0.5798 - val_accuracy: 0.8413 - val_top5_acc: 0.9665\n",
      "Epoch 7/25\n",
      "3212/3212 [==============================] - 142s 44ms/step - loss: 0.5084 - accuracy: 0.8539 - top5_acc: 0.9765 - val_loss: 0.5862 - val_accuracy: 0.8403 - val_top5_acc: 0.9675\n",
      "Epoch 8/25\n",
      "3212/3212 [==============================] - 130s 41ms/step - loss: 0.4965 - accuracy: 0.8564 - top5_acc: 0.9775 - val_loss: 0.5676 - val_accuracy: 0.8434 - val_top5_acc: 0.9690\n",
      "Epoch 9/25\n",
      "3212/3212 [==============================] - 127s 39ms/step - loss: 0.4856 - accuracy: 0.8601 - top5_acc: 0.9784 - val_loss: 0.5585 - val_accuracy: 0.8458 - val_top5_acc: 0.9716\n",
      "Epoch 10/25\n",
      "3212/3212 [==============================] - 127s 40ms/step - loss: 0.4780 - accuracy: 0.8612 - top5_acc: 0.9791 - val_loss: 0.5264 - val_accuracy: 0.8553 - val_top5_acc: 0.9715\n",
      "Epoch 11/25\n",
      "3212/3212 [==============================] - 127s 39ms/step - loss: 0.4707 - accuracy: 0.8622 - top5_acc: 0.9796 - val_loss: 0.5363 - val_accuracy: 0.8547 - val_top5_acc: 0.9711\n",
      "Epoch 12/25\n",
      "3212/3212 [==============================] - 132s 41ms/step - loss: 0.4673 - accuracy: 0.8643 - top5_acc: 0.9802 - val_loss: 0.5336 - val_accuracy: 0.8492 - val_top5_acc: 0.9717\n",
      "Epoch 13/25\n",
      "3212/3212 [==============================] - 123s 38ms/step - loss: 0.4629 - accuracy: 0.8655 - top5_acc: 0.9806 - val_loss: 0.5347 - val_accuracy: 0.8514 - val_top5_acc: 0.9729\n",
      "Epoch 14/25\n",
      "3212/3212 [==============================] - 122s 38ms/step - loss: 0.4568 - accuracy: 0.8670 - top5_acc: 0.9807 - val_loss: 0.5217 - val_accuracy: 0.8552 - val_top5_acc: 0.9719\n",
      "Epoch 15/25\n",
      "3212/3212 [==============================] - 122s 38ms/step - loss: 0.4529 - accuracy: 0.8672 - top5_acc: 0.9818 - val_loss: 0.5275 - val_accuracy: 0.8552 - val_top5_acc: 0.9742\n",
      "Epoch 16/25\n",
      "3212/3212 [==============================] - 121s 38ms/step - loss: 0.4547 - accuracy: 0.8666 - top5_acc: 0.9816 - val_loss: 0.5095 - val_accuracy: 0.8593 - val_top5_acc: 0.9738\n",
      "Epoch 17/25\n",
      "3212/3212 [==============================] - 121s 38ms/step - loss: 0.4442 - accuracy: 0.8697 - top5_acc: 0.9825 - val_loss: 0.5191 - val_accuracy: 0.8530 - val_top5_acc: 0.9741\n",
      "Epoch 18/25\n",
      "3212/3212 [==============================] - 122s 38ms/step - loss: 0.4428 - accuracy: 0.8695 - top5_acc: 0.9828 - val_loss: 0.5419 - val_accuracy: 0.8512 - val_top5_acc: 0.9708\n",
      "Epoch 19/25\n",
      "3212/3212 [==============================] - 121s 38ms/step - loss: 0.4399 - accuracy: 0.8699 - top5_acc: 0.9824 - val_loss: 0.5220 - val_accuracy: 0.8567 - val_top5_acc: 0.9732\n",
      "Epoch 20/25\n",
      "3212/3212 [==============================] - 122s 38ms/step - loss: 0.4405 - accuracy: 0.8710 - top5_acc: 0.9827 - val_loss: 0.5105 - val_accuracy: 0.8595 - val_top5_acc: 0.9721\n",
      "Epoch 21/25\n",
      "3212/3212 [==============================] - 122s 38ms/step - loss: 0.4397 - accuracy: 0.8713 - top5_acc: 0.9823 - val_loss: 0.5046 - val_accuracy: 0.8575 - val_top5_acc: 0.9736\n",
      "Epoch 22/25\n",
      "3212/3212 [==============================] - 122s 38ms/step - loss: 0.4352 - accuracy: 0.8722 - top5_acc: 0.9830 - val_loss: 0.5195 - val_accuracy: 0.8604 - val_top5_acc: 0.9745\n",
      "Epoch 23/25\n",
      "3212/3212 [==============================] - 122s 38ms/step - loss: 0.4306 - accuracy: 0.8716 - top5_acc: 0.9836 - val_loss: 0.5176 - val_accuracy: 0.8614 - val_top5_acc: 0.9717\n",
      "Epoch 24/25\n",
      "3212/3212 [==============================] - 122s 38ms/step - loss: 0.4328 - accuracy: 0.8727 - top5_acc: 0.9835 - val_loss: 0.5036 - val_accuracy: 0.8627 - val_top5_acc: 0.9741\n",
      "Epoch 25/25\n",
      "3212/3212 [==============================] - 122s 38ms/step - loss: 0.4328 - accuracy: 0.8723 - top5_acc: 0.9832 - val_loss: 0.5035 - val_accuracy: 0.8632 - val_top5_acc: 0.9751\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, None, 9)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 120)               46800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 101)               12221     \n",
      "=================================================================\n",
      "Total params: 59,021\n",
      "Trainable params: 59,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Best so far Bi-GRU-100-drop20-recdrop00: 87.7%\n",
    "seq = [\n",
    "    tf.keras.Input(shape=(None,9),ragged=False),\n",
    "    tf.keras.layers.Masking(mask_value=0),\n",
    "    tf.keras.layers.GRU(120,dropout=0.2, recurrent_dropout=0.1, reset_after=False),\n",
    "    tf.keras.layers.Dense(101, activation = \"softmax\"),\n",
    "]\n",
    "seq_no_masking = seq[:1] + seq[2:]\n",
    "\n",
    "keras_model = tf.keras.Sequential(seq)\n",
    "\n",
    "top5_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=5)\n",
    "\n",
    "top5_acc.__name__ = 'top5_acc'\n",
    "\n",
    "keras_model.compile(loss = 'categorical_crossentropy',  optimizer='adam', metrics = ['accuracy', top5_acc])\n",
    "\n",
    "keras_model.fit(X_train, Y_train, epochs = 25 , batch_size = 32, validation_data=(X_val, Y_val))\n",
    "print(keras_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danny/.local/lib/python3.8/site-packages/tensorflowjs/converters/keras_h5_conversion.py:122: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  return h5py.File(h5file)\n"
     ]
    }
   ],
   "source": [
    "predict_model = tf.keras.Sequential(seq_no_masking)\n",
    "predict_model.set_weights(keras_model.get_weights()) \n",
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(predict_model, 'danny_modeljs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.save(\"danny_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "N=1000\n",
    "def time_ms(f):\n",
    "    f() #warm start\n",
    "    return \" %0.6f ms\" % (1000.0*(timeit.timeit(f, number=N)/float(N)))\n",
    "one_character = X_val[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "z9-vVNe9EFag",
    "outputId": "000ca815-31af-40c4-aa9d-7619d873a848"
   },
   "outputs": [],
   "source": [
    "def pred():\n",
    "    keras_model.predict(one_character)\n",
    "    \n",
    "print(time_ms(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQjvak6hEFaj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wJcjGkCEFal"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import GRU, Attention, Input, Concatenate, Dense, TimeDistributed, Activation, dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TqXvWG-EFao"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E (None, 60, 100)\n",
      "Es (None, 100)\n",
      "D (None, 40, 100)\n",
      "A (None, 40, 60)\n",
      "C (None, 40, 100)\n",
      "P (None, 40, 100)\n",
      "Di (None, 1, 101)\n",
      "Ds (None, 100)\n",
      "iD (None, 1, 100)\n",
      "Eio (None, 60, 100)\n",
      "iA (None, 1, 60)\n",
      "iC (None, 1, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "max_curves = 60\n",
    "max_symbols = 40\n",
    "curve_size = 9\n",
    "alphabet_size = 101\n",
    "hidden_size = 100\n",
    "\n",
    "garbage_X = np.random.random((1000,max_curves,curve_size))\n",
    "garbage_Y = np.random.random((1000,max_symbols,alphabet_size))\n",
    "\n",
    "\n",
    "###############################Training Model#######################################\n",
    "encoder_inputs = Input(batch_shape=(None, max_curves, curve_size), name='encoder_inputs')\n",
    "decoder_inputs = Input(batch_shape=(None, max_symbols, alphabet_size), name='decoder_inputs')\n",
    "\n",
    "\n",
    "encoder_gru = GRU(hidden_size, return_sequences=True, return_state=True, reset_after=False, name='encoder_gru')\n",
    "encoder_out, encoder_state = encoder_gru(encoder_inputs)\n",
    "print(\"E\",encoder_out.shape)\n",
    "print(\"Es\",encoder_state.shape)\n",
    "\n",
    "decoder_gru = GRU(hidden_size, return_sequences=True, return_state=True, reset_after=False, name='decoder_gru')\n",
    "decoder_out, decoder_state = decoder_gru(decoder_inputs, initial_state=encoder_state)\n",
    "print(\"D\",decoder_out.shape)\n",
    "\n",
    "#attn_layer = Attention(name='attention_layer')\n",
    "#attn_out = attn_layer([encoder_out, decoder_out])\n",
    "\n",
    "attn_out = dot([decoder_out,encoder_out], axes=[2, 2])\n",
    "attn_out = Activation('softmax')(attn_out)\n",
    "\n",
    "print(\"A\", attn_out.shape)\n",
    "context = dot([attn_out, encoder_out], axes=[2,1])\n",
    "print(\"C\",context.shape)\n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, context])\n",
    "\n",
    "dense = Dense(alphabet_size, activation='softmax', name='softmax_layer')\n",
    "dense_time = TimeDistributed(dense, name='time_distributed_layer')\n",
    "decoder_pred = dense_time(decoder_concat_input)\n",
    "print(\"P\",context.shape)\n",
    "\n",
    "\n",
    "training_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
    "training_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "\n",
    "###############################Encoder Inference#######################################\n",
    "inf_encoder_model = Model(inputs=[encoder_inputs], outputs=[encoder_out, encoder_state])\n",
    "inf_encoder_model.compile()\n",
    "\n",
    "#######################Decoder Inference w/ attention###############################\n",
    "inf_decoder_state = Input(batch_shape=(None, hidden_size), name='inf_decoder_state')\n",
    "inf_decoder_input = Input(batch_shape=(None, 1, alphabet_size), name='inf_decoder_input')\n",
    "inf_encoder_inout = Input(batch_shape=(None, max_curves, hidden_size), name='inf_encoder_inout')\n",
    "\n",
    "print(\"Di\",inf_decoder_input.shape)\n",
    "print(\"Ds\",inf_decoder_state.shape)\n",
    "\n",
    "_inf_decoder_out, _inf_decoder_state = decoder_gru(inf_decoder_input, initial_state=inf_decoder_state)\n",
    "print(\"iD\",_inf_decoder_out.shape)\n",
    "print(\"Eio\",inf_encoder_inout.shape)\n",
    "inf_attn_out = dot([_inf_decoder_out,inf_encoder_inout], axes=[2, 2])\n",
    "inf_attn_out = Activation('softmax')(inf_attn_out)\n",
    "\n",
    "print(\"iA\",inf_attn_out.shape)\n",
    "\n",
    "inf_context = dot([inf_attn_out, inf_encoder_inout], axes=[2,1])\n",
    "print(\"iC\", inf_context.shape)\n",
    "\n",
    "inf_decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([_inf_decoder_out, inf_context])\n",
    "\n",
    "#dense = Dense(alphabet_size, activation='softmax', name='softmax_layer')\n",
    "#dense_time = TimeDistributed(dense, name='time_distributed_layer')\n",
    "inf_decoder_pred = dense_time(inf_decoder_concat_input)\n",
    "\n",
    "inf_decoder_model = Model(inputs=[inf_encoder_inout,inf_decoder_input,inf_decoder_state], outputs=[inf_decoder_pred,_inf_decoder_state,inf_attn_out])\n",
    "inf_decoder_model.compile()\n",
    "#inf_decoder_model = Model(inputs=[encoder_out, encoder_state], outputs=[?])\n",
    "#inf_decoder_input = Input(batch_shape=(None, hidden), name='decoder_inputs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 101)\n"
     ]
    }
   ],
   "source": [
    "start_vec = np.zeros(101,dtype=np.float32)\n",
    "np.put(start_vec,100,1)\n",
    "start_vec = tf.constant(start_vec.reshape(1,1,alphabet_size))\n",
    "end_vec = tf.constant(np.array([0,0,0,0,0,0,0,0,1],dtype=np.float32))\n",
    "print(start_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOESN\"T WORK YET\n",
    "def predict(curves):\n",
    "    '''\n",
    "    encoder_out, encoder_state = encoder_gru(tf.constant(curves), initial_state=tf.zeros([1,hidden_size]))\n",
    "    '''\n",
    "    encoder_out, encoder_state = inf_encoder_model.predict(tf.constant(curves))\n",
    "    print(\"E\",encoder_out.shape)\n",
    "    decoder_inp, decoder_state = start_vec, encoder_state\n",
    "    \n",
    "    \n",
    "    out_symbols = []    \n",
    "    for i in range(10):\n",
    "    #while True:\n",
    "        '''\n",
    "        print(\"D-inp\",decoder_inp.shape)\n",
    "        print(\"D-state\",decoder_state.shape)\n",
    "        decoder_out, decoder_state = decoder_gru(decoder_inp, initial_state=decoder_state)\n",
    "        print(\"D\",decoder_out.shape)\n",
    "        attn_out = dot([decoder_out,encoder_out], axes=[2, 2])\n",
    "        attn_out = Activation('softmax')(attn_out)\n",
    "        \n",
    "        print(\"A\",attn_out.shape)\n",
    "        \n",
    "        context = dot([attn_out, encoder_out], axes=[2,1])\n",
    "        print(\"C\", context.shape)\n",
    "\n",
    "        decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, context])\n",
    "\n",
    "        dense = Dense(alphabet_size, activation='softmax', name='softmax_layer')\n",
    "        dense_time = TimeDistributed(dense, name='time_distributed_layer')\n",
    "        decoder_pred = dense_time(decoder_concat_input)\n",
    "        print(\"P\", decoder_pred.shape)\n",
    "        '''\n",
    "        decoder_pred, decoder_state, attention = inf_decoder_model.predict([encoder_out,decoder_inp, decoder_state])\n",
    "        \n",
    "        max_index = tf.argmax(decoder_pred, -1)\n",
    "        decoder_inp = tf.one_hot(max_index,alphabet_size)\n",
    "        out_symbol = max_index\n",
    "        print(attention)\n",
    "        #decoder_inp = tf.expand_dims(tf.argmax(decoder_pred, -1), 0)\n",
    "        print(out_symbol)\n",
    "        out_symbols.append(out_symbol)\n",
    "        \n",
    "        \n",
    "       # encoder_out = \n",
    "        #out_words.append(fr_tokenizer.index_word[de_input.numpy()[0][0]])\n",
    "        \n",
    "        #alignments.append(alignment.numpy())\n",
    "\n",
    "        #if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
    "        #    break\n",
    "\n",
    "    print(' '.join([str(x.numpy()) for x in out_symbols]))\n",
    "    return out_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 233.2841\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 232.4706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbce82d1670>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.fit([garbage_X, garbage_Y], garbage_Y, epochs = 2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E (1, 60, 100)\n",
      "[[[0.01453928 0.01487747 0.015997   0.01637685 0.01530292 0.01555423\n",
      "   0.01643004 0.0169257  0.01579296 0.01662014 0.01641673 0.01645177\n",
      "   0.01735806 0.01699404 0.01803191 0.01697245 0.01678746 0.01675483\n",
      "   0.01664654 0.016813   0.01772239 0.01721153 0.01621451 0.01621397\n",
      "   0.01719792 0.0173689  0.01685258 0.0164619  0.01702885 0.01775679\n",
      "   0.01727645 0.01696535 0.0168335  0.01694597 0.01725658 0.01653496\n",
      "   0.01703662 0.01690287 0.016323   0.01626301 0.01715383 0.01718754\n",
      "   0.0170712  0.016134   0.01668269 0.01623712 0.0161945  0.0165122\n",
      "   0.01617979 0.0161477  0.01651124 0.01620462 0.01629668 0.01569291\n",
      "   0.01713289 0.01736034 0.0169364  0.01712453 0.01800999 0.01721877]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n",
      "[[[0.01543377 0.0153101  0.01601563 0.01652016 0.0158517  0.01599865\n",
      "   0.01650342 0.01697299 0.01641552 0.01669809 0.01643051 0.01668394\n",
      "   0.0167626  0.01659419 0.01745388 0.01701357 0.01679508 0.01692035\n",
      "   0.01647742 0.01677028 0.01722088 0.01690062 0.01664523 0.01655379\n",
      "   0.01696997 0.01703018 0.01674322 0.01642206 0.01697102 0.0172342\n",
      "   0.01725589 0.01724761 0.01726804 0.01701741 0.01697631 0.01662748\n",
      "   0.01712083 0.01683382 0.01657262 0.01651032 0.01706293 0.0168543\n",
      "   0.01644586 0.01620681 0.01624935 0.01651938 0.01654645 0.01660551\n",
      "   0.01673914 0.01658212 0.01673823 0.01661734 0.01619299 0.01601959\n",
      "   0.0168499  0.01674163 0.01667839 0.01669958 0.01726667 0.01664036]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n",
      "[[[0.01586497 0.01553942 0.01605889 0.01661581 0.01618073 0.01626515\n",
      "   0.01653689 0.01694542 0.01670215 0.01673294 0.01644404 0.01678527\n",
      "   0.01649922 0.01643844 0.01717066 0.01698362 0.01673991 0.01690275\n",
      "   0.01636015 0.01670559 0.01696442 0.01677227 0.01686367 0.01672518\n",
      "   0.016871   0.01687845 0.01667798 0.01642227 0.01690131 0.01698294\n",
      "   0.01722709 0.01734634 0.0174379  0.01702371 0.01683716 0.01670794\n",
      "   0.01718348 0.01680783 0.01670551 0.01658629 0.01694391 0.01669251\n",
      "   0.01620445 0.01628087 0.0161227  0.01666857 0.01669556 0.01663229\n",
      "   0.01697432 0.01680663 0.01683132 0.01678041 0.01615161 0.01619496\n",
      "   0.01668751 0.01646135 0.01657979 0.01654818 0.01694781 0.01640047]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n",
      "[[[0.01606574 0.01565923 0.01608826 0.01667788 0.01637509 0.01642339\n",
      "   0.01655671 0.0169033  0.01683059 0.01674538 0.0164499  0.01682604\n",
      "   0.01638255 0.01637275 0.01702335 0.01694818 0.01669193 0.01686011\n",
      "   0.01629239 0.01665024 0.01683086 0.0167104  0.01697696 0.01681304\n",
      "   0.01682878 0.01680906 0.01664168 0.01643407 0.01684394 0.01685997\n",
      "   0.01720427 0.01737702 0.01749614 0.01700803 0.01675984 0.01676259\n",
      "   0.01721805 0.01679818 0.01678069 0.01660896 0.01685051 0.01661048\n",
      "   0.01611445 0.01633747 0.01610013 0.01674519 0.01675712 0.01664015\n",
      "   0.01706721 0.01692719 0.01687837 0.0168455  0.01614099 0.01630253\n",
      "   0.01660598 0.01634112 0.01654838 0.01649903 0.0168035  0.01629909]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n",
      "[[[0.01615539 0.01571995 0.01610162 0.01671666 0.01648557 0.016513\n",
      "   0.01656848 0.01686667 0.01688557 0.01674826 0.01645065 0.01684096\n",
      "   0.01633335 0.01634177 0.0169448  0.01692346 0.01666269 0.01683094\n",
      "   0.01625713 0.01661023 0.01676115 0.01667531 0.01703585 0.01685742\n",
      "   0.01681161 0.01677742 0.01662337 0.01644698 0.0168045  0.01680123\n",
      "   0.01718917 0.01738435 0.01751053 0.01698845 0.01671406 0.01679529\n",
      "   0.01723328 0.01679445 0.01682462 0.01661664 0.01678935 0.01656819\n",
      "   0.01608395 0.01637544 0.01610713 0.01678211 0.01677988 0.0166429\n",
      "   0.01709974 0.01699208 0.01690625 0.01687109 0.01614239 0.01637179\n",
      "   0.01657021 0.01629433 0.01654269 0.01648583 0.01673559 0.01625622]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n",
      "[[[0.01619311 0.01574946 0.01610468 0.01674011 0.01654588 0.01656112\n",
      "   0.01657511 0.01683981 0.01690731 0.01674779 0.01644946 0.01684566\n",
      "   0.01631485 0.01632525 0.0169028  0.01690954 0.01664793 0.016817\n",
      "   0.01624019 0.01658316 0.01672489 0.01665294 0.0170663  0.01687946\n",
      "   0.01680558 0.01676327 0.01661535 0.01645769 0.01678005 0.01677471\n",
      "   0.01718008 0.01738484 0.01750958 0.0169714  0.0166862  0.01681374\n",
      "   0.01723823 0.01679279 0.01685089 0.0166205  0.0167528  0.01654623\n",
      "   0.01607562 0.01639914 0.01611869 0.01679837 0.0167862  0.01664452\n",
      "   0.01710807 0.01702651 0.0169243  0.01688055 0.01614689 0.01641654\n",
      "   0.01655733 0.01627931 0.01654542 0.01648397 0.0167024  0.0162384 ]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n",
      "[[[0.01620746 0.01576298 0.01610268 0.0167539  0.01657757 0.0165856\n",
      "   0.01657866 0.01682165 0.01691462 0.01674652 0.01644806 0.0168467\n",
      "   0.01630968 0.01631553 0.0168806  0.0169029  0.01664174 0.01681264\n",
      "   0.01623269 0.01656535 0.01670611 0.01663784 0.01708193 0.0168903\n",
      "   0.01680437 0.01675716 0.01661273 0.01646565 0.01676589 0.0167639\n",
      "   0.01717491 0.01738402 0.01750457 0.0169584  0.01666912 0.01682397\n",
      "   0.01723867 0.01679186 0.01686691 0.01662336 0.0167321  0.01653477\n",
      "   0.01607466 0.0164133  0.01612792 0.01680457 0.01678628 0.01664595\n",
      "   0.01710769 0.01704436 0.01693644 0.01688351 0.01615109 0.0164451\n",
      "   0.01655463 0.01627682 0.01654993 0.01648494 0.01668547 0.01623134]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n",
      "[[[0.01621181 0.01576861 0.01609891 0.01676184 0.01659361 0.01659731\n",
      "   0.01658051 0.01680994 0.01691606 0.01674532 0.01644706 0.01684663\n",
      "   0.01630973 0.01630946 0.01686909 0.01690039 0.01663988 0.01681293\n",
      "   0.01622972 0.01655375 0.01669641 0.01662748 0.01708986 0.01689568\n",
      "   0.01680508 0.01675467 0.01661261 0.01647122 0.01675809 0.01676031\n",
      "   0.01717205 0.01738339 0.01749947 0.01694913 0.01665867 0.01682973\n",
      "   0.01723758 0.01679122 0.01687686 0.01662574 0.01672077 0.01652874\n",
      "   0.01607556 0.01642149 0.01613397 0.01680626 0.01678453 0.01664732\n",
      "   0.01710488 0.01705336 0.01694468 0.016884   0.0161541  0.01646305\n",
      "   0.01655574 0.01627848 0.01655397 0.01648613 0.01667641 0.01622881]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n",
      "[[[0.01621226 0.01577055 0.01609502 0.01676632 0.0166014  0.01660251\n",
      "   0.01658147 0.01680262 0.01691545 0.01674439 0.01644651 0.01684633\n",
      "   0.01631141 0.01630558 0.01686328 0.01689989 0.01663989 0.01681488\n",
      "   0.01622875 0.01654621 0.01669139 0.0166204  0.01709384 0.01689842\n",
      "   0.01680636 0.01675374 0.01661347 0.01647496 0.01675396 0.01675978\n",
      "   0.01717051 0.01738315 0.01749545 0.01694277 0.01665229 0.01683309\n",
      "   0.01723626 0.01679075 0.01688312 0.01662767 0.01671472 0.01652553\n",
      "   0.01607653 0.01642613 0.01613754 0.01680618 0.01678267 0.01664855\n",
      "   0.01710198 0.01705772 0.01695026 0.01688366 0.016156   0.01647417\n",
      "   0.01655783 0.01628095 0.01655703 0.01648696 0.01667131 0.01622812]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n",
      "[[[0.01621144 0.01577091 0.01609173 0.01676881 0.01660503 0.01660457\n",
      "   0.016582   0.01679814 0.01691433 0.01674375 0.01644629 0.01684607\n",
      "   0.01631327 0.0163031  0.01686046 0.01690023 0.01664054 0.01681706\n",
      "   0.0162286  0.01654134 0.0166888  0.01661562 0.0170958  0.0168999\n",
      "   0.01680765 0.01675347 0.01661454 0.01647741 0.01675185 0.01676032\n",
      "   0.0171697  0.0173832  0.01749259 0.01693854 0.01664844 0.01683514\n",
      "   0.01723517 0.0167904  0.01688712 0.01662916 0.01671154 0.01652379\n",
      "   0.01607714 0.01642871 0.0161395  0.01680556 0.01678123 0.0166496\n",
      "   0.01709969 0.01705974 0.01695401 0.01688315 0.01615708 0.01648097\n",
      "   0.01655978 0.01628308 0.01655917 0.01648742 0.0166683  0.01622811]]]\n",
      "tf.Tensor([[97]], shape=(1, 1), dtype=int64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, tensorflow.python.framework.ops.EagerTensor found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0a045cc492a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgarbage_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-99edc5db5a00>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(curves)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#    break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_symbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout_symbols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, tensorflow.python.framework.ops.EagerTensor found"
     ]
    }
   ],
   "source": [
    "predict(garbage_X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(full_model, 'danny_nmt_modeljs')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trainingF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
